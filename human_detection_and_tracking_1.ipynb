{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading YOLO algorigthm\n",
    "weights = r'C:\\Users\\sidth\\Desktop\\Human_detection_tracking_codes\\yolov3.weights'\n",
    "config_file = r'C:\\Users\\sidth\\Desktop\\Human_detection_tracking_codes\\yolov3.cfg'\n",
    "net = cv2.dnn.readNet(weights,config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r'C:\\Users\\sidth\\Desktop\\Human_detection_tracking_codes\\coco.names') as f:\n",
    "#     classes = [line.strip() for line in f.readlines()]\n",
    "#     #Putiing the classes into a list\n",
    "classes = [\"person\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the image\n",
    "# img = cv2.imread(r'C:\\Users\\sidth\\Desktop\\Human_detection_tracking_codes\\people_walking.jpg')\n",
    "cap = cv2.VideoCapture(r'C:\\Users\\sidth\\Desktop\\Human_detection_tracking_codes\\test2.mp4')\n",
    "while True:\n",
    "    _, img = cap.read()\n",
    "#     img = cv2.resize(img,None,fx= 0.2,fy =0.2)\n",
    "    height, width, _ = img.shape\n",
    "    blob = cv2.dnn.blobFromImage(img,1/255,(416,416),(0,0,0),swapRB =True,crop = False)\n",
    "    net.setInput(blob)\n",
    "    output_layers = net.getUnconnectedOutLayersNames()\n",
    "    layer_names_output = net.forward(output_layers)\n",
    "    # net.forward is used to run the forward pass and obtain the output at output layers\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "\n",
    "    for output in layer_names_output:\n",
    "        for detection in output:\n",
    "    #      total 85 parameter(80 classes and 4 bounding box offest 1 confidendce) for each detection in output\n",
    "            scores = detection[5:] \n",
    "    #      scores variable to extract all 80 classes prediction stariting from 6th ele to the end\n",
    "            class_id = np.argmax(scores)\n",
    "    #      location that contain the max score in scores\n",
    "            confidence = scores[class_id]\n",
    "    #      extract the high sce and save it in confidence\n",
    "            if confidence > 0.5:\n",
    "                    center_x = int(detection[0] * width)\n",
    "                    center_y = int(detection[1] * height)\n",
    "                    w = int(detection[2] * width)\n",
    "                    h = int(detection[3] * height)\n",
    "    #               to cover the left corner\n",
    "                    x  = int(center_x - w/2)\n",
    "                    y = int(center_y - w/2)\n",
    "                    boxes.append([x,y,w,h])\n",
    "                    confidences.append((float(confidence)))\n",
    "                    class_ids.append((class_id))\n",
    "\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes,confidences,0.5,0.4)\n",
    "    # to remove redunucy.\n",
    "    font = cv2.FONT_HERSHEY_COMPLEX\n",
    "    colors = np.random.uniform(0,255,size = (len(boxes),3))\n",
    "    if len(indexes)>0:\n",
    "        for i in indexes.flatten():\n",
    "            x,y,w,h = boxes[i]\n",
    "            label = \"person\"\n",
    "            confidence = str(round(confidences[i],2))\n",
    "            color = colors[i]\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),color,2)\n",
    "            cv2.putText(img,label+ \" \"+ confidence,(x,y+20),font,1,(255,0,0),1)\n",
    "\n",
    "    cv2.imshow('image1',img)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "                \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
